# ğŸŒ¸ Serenity Speaks Bot ğŸŒ¸

Welcome to the ğŸŒ¸ Serenity Speaks Bot ğŸŒ¸ repository! This project, developed by Apollo Analytics, utilizes state-of-the-art technology to provide a personalized and secure mental wellness companion. Powered by Flowise and Ollama's Llama3 model, this bot offers an interactive and intuitive interface for users seeking mental health support.

## Installation

### Prerequisites
Before installing Flowise, you will need Node.js installed on your machine. You can install Node.js from the [Node.js Download Link](https://nodejs.org/en/download/package-manager).

### Installing Flowise
With Node.js installed, open your terminal or command prompt and run the following commands:

```bash
npm install -g flowise
npx flowise start
```

After running these commands, Flowise should be up and running ğŸš€. You can access it by navigating to [http://localhost:3000](http://localhost:3000).

## Importing Serenity Speaks Bot Chatflow ğŸ“¥
To import the Serenity Speaks Bot Chatflow:

1. Go to [http://localhost:3000](http://localhost:3000) ğŸŒ.
2. Navigate to the Chatflows section from the sidebar menu and click "Add New" ğŸ†•.
3. Click the settings icon, then select "Load Chatflow" âš™ï¸.
4. Navigate to where the `Serenity Speaks Bot - Apollo Analytics.json` chatflow file is located and load it ğŸ“‚.
5. Save the chatflow by clicking the save button and assigning a filename ğŸ’¾.

## Setting Up Ollama and Llama3 ğŸ› ï¸
To use Llama3 locally:

1. Download Ollama from [this link](https://ollama.com/download) and run the executable file ğŸ“¦.
2. Open your terminal and run the following commands to install and serve the Llama3 model:

```bash
ollama run llama3
ollama serve
```

Now, you are all set to chat with your chatbot using the purple chat icon on your local machine ğŸ’œ.

## Using the Bot ğŸ—¨ï¸
Once everything is set up, you can start interacting with Serenity Speaks Bot by using the chat interface in Flowise. This setup ensures that all interactions are secure and private, with the bot's responses powered by the locally hosted Llama3 model.

## Support ğŸ› ï¸
If you encounter any issues or have questions about the setup, please open an issue in this repository. We are here to help!

Thank you for supporting Serenity Speaks Bot! ğŸŒŸ
